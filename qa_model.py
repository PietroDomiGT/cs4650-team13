# -*- coding: utf-8 -*-
"""QA_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n4bNZc61XAmuOaSoD_n1kIFNCRzeCzoP
"""

from google.colab import drive
drive.mount('/content/drive')

drive_path = "/content/drive/My Drive/NLP project/"

import numpy
import pandas
import torch
import nltk
from nltk import word_tokenize, sent_tokenize#, regexp_tokenize
from torch import nn, optim
from torchtext import data
from torchtext.vocab import GloVe
nltk.download('punkt')

import time

with open(drive_path+"data/data_slp_v2.txt",'r',encoding='utf8') as p:
    text = p.read()

abnormals = ['\ufeff','\n']
chars = []
clean = ""
for w in text:
    if w not in abnormals:
        if w != " ":
            chars.append(w)
        clean += w

tokens = word_tokenize(clean)
sent = sent_tokenize(clean)

print(sent[:100])
print(tokens[:100])
print(chars[:100])

# TODO improve efficiency with torchtext

#char_vocab = sorted(set(chars))
#word_vocab = sorted(set(tokens))

RAW = data.RawField()
RAW.is_target = False
CHAR_NESTING = data.Field(batch_first=True, tokenize=list, lower=True)
CHAR = data.NestedField(CHAR_NESTING, tokenize=word_tokenize)
WORD = data.Field(batch_first=True, tokenize=word_tokenize, lower=True, include_lengths=True)
LABEL = data.Field(sequential=False, unk_token=None, use_vocab=False)

list_fields = [('id', RAW), ('s_idx', LABEL), ('e_idx', LABEL),
                       ('c_word', WORD), ('c_char', CHAR),
                       ('q_word', WORD), ('q_char', CHAR)]

train_text = {"context":text, question:"What plays a crucial role in natural language processing?", answer:"the simple pattern-based methods"}]

train_data = data.Dataset(examples=text, fields=list_fields)



WORD.build_vocab(text, vectors=GloVe(name='6B', dim=300))
CHAR.build_vocab(text)

import pickle
with open(drive_path+"working/WORD_CHAR_vocab.pickle",'wb') as p:
    pickle.dump((WORD, CHAR), p)

# Utils.py

class LSTM(nn.Module):
    def __init__(self, input_size, hidden_size, batch_first=False, num_layers=1, bidirectional=False, dropout=0.2):
        super(LSTM, self).__init__()

        self.rnn = nn.LSTM(input_size=input_size,
                           hidden_size=hidden_size,
                           num_layers=num_layers,
                           bidirectional=bidirectional,
                           batch_first=batch_first)
        self.reset_params()
        self.dropout = nn.Dropout(p=dropout)

    def reset_params(self):
        for i in range(self.rnn.num_layers):
            nn.init.orthogonal_(getattr(self.rnn, f'weight_hh_l{i}'))
            nn.init.kaiming_normal_(getattr(self.rnn, f'weight_ih_l{i}'))
            nn.init.constant_(getattr(self.rnn, f'bias_hh_l{i}'), val=0)
            nn.init.constant_(getattr(self.rnn, f'bias_ih_l{i}'), val=0)
            getattr(self.rnn, f'bias_hh_l{i}').chunk(4)[1].fill_(1)

            if self.rnn.bidirectional:
                nn.init.orthogonal_(getattr(self.rnn, f'weight_hh_l{i}_reverse'))
                nn.init.kaiming_normal_(getattr(self.rnn, f'weight_ih_l{i}_reverse'))
                nn.init.constant_(getattr(self.rnn, f'bias_hh_l{i}_reverse'), val=0)
                nn.init.constant_(getattr(self.rnn, f'bias_ih_l{i}_reverse'), val=0)
                getattr(self.rnn, f'bias_hh_l{i}_reverse').chunk(4)[1].fill_(1)

    def forward(self, x):
        x, x_len = x
        x = self.dropout(x)

        x_len_sorted, x_idx = torch.sort(x_len, descending=True)
        x_sorted = x.index_select(dim=0, index=x_idx)
        _, x_ori_idx = torch.sort(x_idx)

        x_packed = nn.utils.rnn.pack_padded_sequence(x_sorted, x_len_sorted, batch_first=True)
        x_packed, (h, c) = self.rnn(x_packed)

        x = nn.utils.rnn.pad_packed_sequence(x_packed, batch_first=True)[0]
        x = x.index_select(dim=0, index=x_ori_idx)
        h = h.permute(1, 0, 2).contiguous().view(-1, h.size(0) * h.size(2)).squeeze()
        h = h.index_select(dim=0, index=x_ori_idx)

        return x, h


class Linear(nn.Module):
    def __init__(self, in_features, out_features, dropout=0.0):
        super(Linear, self).__init__()

        self.linear = nn.Linear(in_features=in_features, out_features=out_features)
        if dropout > 0:
            self.dropout = nn.Dropout(p=dropout)
        self.reset_params()

    def reset_params(self):
        nn.init.kaiming_normal_(self.linear.weight)
        nn.init.constant_(self.linear.bias, 0)

    def forward(self, x):
        if hasattr(self, 'dropout'):
            x = self.dropout(x)
        x = self.linear(x)
        return x

class BiDAF(nn.Module):
    def __init__(self, args, pretrained):
        super(BiDAF, self).__init__()
        self.args = args

        # Character embedding layer
        self.char_emb = nn.Embedding(args.char_vocab_size, args.char_dim)
        nn.init.uniform_(self.char_emb.weight, -0.001, 0.001)   # set the weights close to zero

        self.char_conv = nn.Sequential(     # apply a convolution on the characters to capture meaning in word parts
            nn.Conv1d(1, args.char_channel_size, (args.char_dim, args.char_channel_width)),
            nn.ReLU()
        )

        # Word Embedding Layer from GloVe
        self.word_emb = nn.Embedding.from_pretrained(pretrained)

        # highway network
        assert self.args.hidden_size * 2 == (self.args.char_channel_size + self.args.word_dim)
        for i in range(2):
            setattr(self, f"highway_linear{i}",
                    nn.Sequential(Linear(args.hidden_size*2,args.hidden_size*2),
                                  nn.ReLU()))
            setattr(self, f"highway_gate{i}",
                    nn.Sequential(Linear(args.hidden_size*2,args.hidden_size*2),
                                  nn.Sigmoid()))
        
        # Contextual Embedding Layer
        self.context_LSTM = LSTM(input_size=args.hidden_size*2,
                                 hidden_size=args.hidden_size,
                                 batch_first=True,
                                 bidirectional=True,
                                 dropout=args.dropout)
        
        # Attention Flow Layer
        self.att_weight_c = Linear(args.hidden_size * 2, 1)
        self.att_weight_q = Linear(args.hidden_size * 2, 1)
        self.att_weight_cq = Linear(args.hidden_size * 2, 1)

        # Modeling Layer
        self.modeling_LSTM1 = LSTM(input_size=args.hidden_size * 8,
                                   hidden_size=args.hidden_size,
                                   bidirectional=True,
                                   batch_first=True,
                                   dropout=args.dropout)
        
        self.modeling_LSTM2 = LSTM(input_size=args.hidden_size * 2,
                                   hidden_size=args.hidden_size,
                                   bidirectional=True,
                                   batch_first=True,
                                   dropout=args.dropout)

        # Output Layer
        self.p1_weight_g = Linear(args.hidden_size * 8, 1, dropout=args.dropout)
        self.p1_weight_m = Linear(args.hidden_size * 2, 1, dropout=args.dropout)
        self.p2_weight_g = Linear(args.hidden_size * 8, 1, dropout=args.dropout)
        self.p2_weight_m = Linear(args.hidden_size * 2, 1, dropout=args.dropout)

        self.output_LSTM = LSTM(input_size=args.hidden_size * 2,
                                hidden_size=args.hidden_size,
                                bidirectional=True,
                                batch_first=True,
                                dropout=args.dropout)

        self.dropout = nn.Dropout(p=args.dropout)

    def forward(self, batch):
        def char_emb_layer(x):
            batch_size = x.size(0)
            x = self.dropout(self.char_emb(x))
            x = x.transpose(2,3)
            x = x.view(-1, self.args.char_dim, x.size(3)).unsqueeze(1)
            x = self.char_conv(x).squeeze()
            x = F.max_pool1d(x, x.size(2)).squeeze()
            x = x.view(batch_size, -1, self.args.char_channel_size)

            return x

        def highway_network(x1, x2):
            x = torch.cat([x1,x2], dim=-1)
            for i in range(2):
                h = getattr(self, f"highway_linear{i}")(x)
                g = getattr(self, f"highway_gate{i}")(x)
                x = g * h + (1-g) * x
            return x

        def att_flow_layer(c, q):

            c_len = c.size(1)
            q_len = q.size(1)

            cq = []
            for i in range(q_len):
                qi = q.select(1, i).unsqueeze(1)
                ci = self.att_weight_cq(c * qi).squeeze()
                cq.append(ci)
            cq = torch.stack(cq, dim=-1)

            s = self.att_weight_c(c).expand(-1, -1, q_len) + \
                self.att_weight_q(q).permute(0, 2, 1).expand(-1, c_len, -1) + \
                cq

            a = F.softmax(s, dim=2)
            c2q_att = torch.bmm(a,q)
            b = F.softmax(torch.max(s, dim=2)[0], dim=1).unsqueeze(1)
            q2c_att = torch.bmm(b, c).squeeze()
            q2c_att = q2c_att.unsqueeze(1).expand(-1, c_len, -1)

            x = torch.cat([c, c2q_att, c* c2q_att, c* q2c_att], dim=-1)
            return x

        def output_layer(g, m, l):

            p1 = (self.p1_weight_g(g) + self.p1_weight_m(m)).squeeze()
            m2 = self.output_LSTM((m, l))[0]
            p2 = (self.p2_weight_g(g) + self.p2_weight_m(m2)).squeeze()
            
            return p1, p2

        # 1. Character Embedding Layer
        c_char = char_emb_layer(batch.c_char)
        q_char = char_emb_layer(batch.q_char)
        # 2. Word Embedding Layer
        c_word = self.word_emb(batch.c_word[0])
        q_word = self.word_emb(batch.q_word[0])
        c_lens = batch.c_word[1]
        q_lens = batch.q_word[1]

        # Highway network
        c = highway_network(c_char, c_word)
        q = highway_network(q_char, q_word)
        # 3. Contextual Embedding Layer
        c = self.context_LSTM((c, c_lens))[0]
        q = self.context_LSTM((q, q_lens))[0]
        # 4. Attention Flow Layer
        g = att_flow_layer(c, q)
        # 5. Modeling Layer
        m = self.modeling_LSTM2((self.modeling_LSTM1((g, c_lens))[0], c_lens))[0]
        # 6. Output Layer
        p1, p2 = output_layer(g, m, c_lens)

        # (batch, c_len), (batch, c_len)
        return p1, p2

# train.py
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
train_iter = data.BucketIterator(
    
)